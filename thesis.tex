\documentclass[final,oneside]{vutinfth}

% Load packages to allow in- and output of non-ASCII characters.
\usepackage{lmodern}        % Use an extension of the original Computer Modern font to minimize the use of bitmapped letters.
\usepackage[T1]{fontenc}    % Determines font encoding of the output. Font packages have to be included before this line.
\usepackage[utf8]{inputenc} % Determines encoding of the input. All input files have to use UTF8 encoding.

% Extended LaTeX functionality is enables by including packages with \usepackage{...}.
\usepackage[inline]{enumitem} % User control over the layout of lists (itemize, enumerate, description).
\usepackage{multirow}   % Allows table elements to span several rows.
\usepackage{booktabs}   % Improves the typesetting of tables.
\usepackage{subcaption} % Allows the use of subfigures and enables their referencing.
\usepackage{minted}
\usepackage[usenames,dvipsnames,table]{xcolor} % Allows the definition and use of colors. This package has to be included before tikz.
\usepackage{nag}       % Issues warnings when best practices in writing LaTeX documents are violated.
\usepackage{todonotes} % Provides tooltip-like todo notes.
\usepackage{hyperref}  % Enables hyperlinking in the electronic document version. This package has to be included second to last.
\usepackage[acronym,toc]{glossaries} % Enables the generation of glossaries and lists of acronyms. This package has to be included last.
\usepackage{listings, listings-rust, listings-json, listings-url} % Code
\usepackage{hyperref}
\lstset{
    basicstyle=\ttfamily,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
    breaklines=true
}

% Define convenience functions here:
\newcommand{\authorname}{Jannis Adamek}
\newcommand{\thesistitle}{TODO: title}
\newcommand{\thesistitlegerman}{TODO: title deutsch}

\newcommand{\rustsnippet}[1]{\lstinline[language=rust]{#1}}
\newcommand{\bashsnippet}[1]{\lstinline[language=bash]{#1}}
\newcommand{\pythonsnippet}[1]{\lstinline[language=python]{#1}}
\newcommand{\urlsnippet}[1]{\lstinline[language=url]{#1}}

% Set PDF document properties
\hypersetup{
    pdfpagelayout   = TwoPageRight,           % How the document is shown in PDF viewers (optional).
    linkbordercolor = {Melon},                % The color of the borders of boxes around hyperlinks (optional).
    pdfauthor       = {\authorname},          % The author's name in the document properties (optional).
    pdftitle        = {\thesistitle},         % The document's title in the document properties (optional).
    pdfsubject      = {TODO: subject},        % The document's subject in the document properties (optional).
    pdfkeywords     = {TODO, list, of, keywords} % The document's keywords in the document properties (optional).
}

\setpnumwidth{2.5em}        % Avoid overfull hboxes in the table of contents (see memoir manual).
\setsecnumdepth{subsection} % Enumerate subsections.

\nonzeroparskip             % Create space between paragraphs (optional).
\setlength{\parindent}{0pt} % Remove paragraph indentation (optional).

\makeindex      % Use an optional index.
\makeglossaries % Use an optional glossary.

% Set persons with 4 arguments:
%  {title before name}{name}{title after name}{gender}
%  where both titles are optional (i.e. can be given as empty brackets {}).
\setauthor{}{\authorname}{}{male}
\setadvisor{Univ.Lektor Dipl.-Ing. Dr.techn.}{Markus Raab}{}{male}

\setregnumber{11809490}
% TODO: set date
\setdate{27}{10}{2024} % Set date with 3 arguments: {day}{month}{year}.
\settitle{\thesistitle}{\thesistitlegerman}
% \setsubtitle{Optional Subtitle of the Thesis}{Optionaler Untertitel der Arbeit} % Sets English and German version of the subtitle (both can be English or German).

\setthesis{bachelor}

% For bachelor and master:
\setcurriculum{Software \& Information Engineering}{Software \& Information Engineering}

\begin{document}

\frontmatter

\addtitlepage{naustrian}
\addtitlepage{english}
\addstatementpage

\begin{acknowledgements*}
I would like to extend my gratitude to the entire PermaplanT team for the fantastic collaboration.
It has been a pleasure working with all of them.
My deepest appreciation goes to my professor, Dr.techn. Markus Raab, for his guidance, advice and patience throughout this process.
A special thanks to MSc Yvonne Markl for her invaluable Permaculture expertise and positive energy.
Lastly, I am thankful to my wonderful partner, Natashia, for her constant encouragement and for helping me stay balanced during this journey.
\end{acknowledgements*}

\begin{abstract}
PermaplanT is a web application for collaborative garden planning featuring a real-time synchronized Map Editor.
A race condition in the broadcasting mechanism can cause clients to receive actions (change events) in the wrong order, leading to inconsistencies between the state displayed to users and the state stored in the database.
Additionally, PermaplanT must scale to support at least 100 concurrent users without performance degradation.
Using Python script, we conducted two tests: a performance test to measure response times with increasing numbers of concurrent connections, and a correctness test to detect cases where broadcasted actions arrived out of order.
The performance test showed that that the system could handle 100 concurrent users, with increasing response times beyond 1000 connections.
The correctness test confirmed that race conditions can indeed lead to event ordering issues.
We present a possible solution to fix the race condition.
\end{abstract}

\selectlanguage{english}

% Acronyms go here
\newacronym{tcp}{TCP}{Transmission Control Protocol}
\newacronym{http}{HTTP}{Hypertext Transfer Protocol}
\newacronym{sse}{SSE}{Server Sent Events}
\newacronym{json}{JSON}{JavaScript Object Notation}
\newacronym{uuid}{UUID}{Universally Unique Identifier}
\newacronym{io}{I/O}{Input Output}

\tableofcontents % Starred version, i.e., \tableofcontents*, removes the self-entry.

% Switch to arabic numbering and start the enumeration of chapters in the table of content.
\mainmatter

\chapter{Introduction}

\section{PermaplanT}

PermaplanT (\url{https://www.permaplant.net}) is an innovative web application that strives to help users plan gardening spaces following the principles of permaculture.
The application uses a web application architecture consisting of a client-side frontend running in the user's web browser and a server-side backend.
The frontend is built using JavaScript and the React framework, while the backend is developed in Rust, backed by the relational database PostgreSQL for data storage.
In addition to the actual application, PermaplanT features a dataset of about 10,000 plant records with information about life cycles, fertility, light and water requirements, and plant relationships.

\section{The Collaborative Map Editor}

The central feature of PermaplanT is its Map Editor, a garden planning tool that allows users to add, remove, and manage garden elements including plants, soil textures, and shading.
To support collaborative garden design, the Map Editor is fully synchronized, so that changes made by one user are reflected in real time on all clients viewing the same map. This is achieved by sending change events, which we will refer to as \emph{actions}.

\section{Research Objective}

In this thesis, we evaluate the performance and correctness of the action broadcasting mechanism within the PermaplanT Map Editor.
One of PermaplanT's non-functional requirements is to support up to 100 concurrent users making changes to the same map without degrading in response times.
We test whether the current implementation of the action broadcasting mechanism adequately achieves this scalability goal.

In terms of correctness, we will test if the sequence of database updates aligns with the sequence of actions that the client receives.
Some actions are order-dependent, e.g. two actions that move the same planting (an instance of a plant on the map) to an absolute position, or an action that moves a planting and another that deletes the same planting.
If actions can arrive out of order, then the state of the client and the state of the database will become inconsistent until the user refreshes the Map Editor page.

In summary, this thesis answers the following questions:
\begin{enumerate}
  \item \textbf{Performance}: How does the duration of \gls{http} requests that modify the state of a map correlate with the number of concurrent users that receive the broadcasted actions on the same map?
  \item \textbf{Correctness}: Is the order of actions that the client receives always in the same order as the respective database writes? 
\end{enumerate}

\chapter{Background}

\section{Map Updates and State Broadcasting}

When a user opens the Map Editor in their web browser, the frontend sends a \texttt{GET} request to the \gls{http} endpoint at the URL \urlsnippet{/api/updates/maps}.
This establishes a unidirectional stream from the server to the client using \gls{sse}.
Through this stream, the client receives map updates in the format \gls{json} referred to as \emph{actions} within PermaplanT.
Each action has a \texttt{type} field, which defines what information it carries.
For example, actions that affect plantings on the map include the following types:
\begin{itemize}
    \item \texttt{CreatePlanting} creates one or more new plantings.
    \item \texttt{MovePlanting} updates the position (x,y) of one or more plantings on the map.
    \item\texttt{TransformPlanting} changes the size of one or more plantings on the map.
\end{itemize}

For each \gls{http} endpoint that modifies the state of the map, the frontend includes a client-generated \gls{uuid} called \texttt{actionId} in the request body.
The backend validates the request, makes the necessary changes to the PostgreSQL database, and then broadcasts the changes via the appropriate action to all open streams that belong to the same map.
\texttt{actionId} is generated by the frontend so that the client can recognize and ignore actions that were caused by its own updates.

\subsection{Map Update Example}

For example, to move one or more plantings, the client makes an \gls{http} \texttt{PATCH} request to \urlsnippet{/api/maps/<map_id>/layers/plants/plantings} with the desired map identifier and the following \gls{json} payload.

\begin{minipage}{\linewidth}
\begin{lstlisting}[language=json]
{
  "actionId": "<action_id>",
  "dto": {
    "type": "move",
    "content": [
      {
        "id": "<planting_uuid_1>",
        "x": 10,
        "y": 10
      },
      {
        "id": "<planting_uuid_2>",
        "x": 20,
        "y": 20
      }
    ]
  }
}
\end{lstlisting}
\end{minipage}

This request sets the absolute positions of two plantings.

\section{Race Condition in the Broadcasting Mechanism}

All \gls{http} endpoints in the backend follow the steps of the following simplified illustration in Rust.

\begin{minipage}{\linewidth}
\begin{lstlisting}[language=rust]
async update_plantings(
    map_id: i32,
    update: UpdatePlantingDto,
) -> Result<HttpResponse> {
    // Updates the PostgreSQL database
    let updated = plantings::update(map_id, update).await;
    // Broadcast out the state change to all users
    broadcaster.broadcast(map_id, updated).await;
    // Finishes the HTTP request
    return HttpResponse::Ok().json(updated);
}
\end{lstlisting}
\end{minipage}

In asynchronous Rust, each \rustsnippet{async} function is converted into a state machine that stores the intermediate states from which the function can be suspended and resumed at a later time. 
These suspension entry points are denoted by the expressions \rustsnippet{await}.
This allows asynchronous functions to return back control to the runtime, which may continue with the same function or schedule other tasks concurrently\cite{rustasyncdeepdive2024}.

Asynchronous Rust code is best suited for \gls{io} heavy application.
To achieve effective concurrency, runtime libraries employ a small number of operating system threads, each of which can handle many concurrent tasks\cite{rustasyncbookchapter}. 

In contrast to other programming environments like JavaScript running in the web browser\cite{mdnjavascripteventloop}, Rust doesn't provide any default asynchronous runtime implementation.
PermaplanT uses the runtime library Tokio \cite{tokiocrate} to execute asynchronous Rust code.

Since Rust's asynchronous functions give up control, other tasks may run in between two \rustsnippet{await} statements.
Two update requests can interleave, which can cause actions to be broadcasted to the client in the wrong order.
To illustrate the race condition,
\begin{enumerate}
    \item User 1 makes the \gls{http} request \textit{R1} to move the planting to (100, 100).
    \item User 2 makes the \gls{http} request \textit{R2} to move the same planting to (200, 200).
    \item \rustsnippet{plantings::update().await} finishes in \textit{R1} and stores (100, 100) \
    in the database. The function suspends and the runtime starts executing \textit{R2}.
    \item \textit{R2} finished the entire request, it stores (200, 200) in the database and broadcasts (200, 200) to the client.
    \item Finally, \textit{R1} resumes execution and broadcasts (100, 100).
\end{enumerate}

In this way, the final entry in the database is (200, 200) but the actions are sent in this order: (200, 200) and then (100, 100).
The client incorrectly displays the planting at (100, 100).

\subsection{Critical Section}

As explained by Dubey et al.\cite{artice_race_condition_and_dynamic_data_race_detection}, a race condition occurs when concurrent threads access shared resources without synchronization.
The part of the code that handles the shared resources is called a \textbf{Critical Section}.
In our case, the database update and broadcasting form a critical section together.
Without mutual exclusion, both tasks can occur out of order, leading to inconsistent results.
The article \cite{artice_race_condition_and_dynamic_data_race_detection} further explains that any solution, that deals with securing of critical sections is judged via two mandatory criteria: 
\begin{enumerate}
    \item \textbf{Mutual Exclusion}
    Only one thread should enter the critical section at one given time.
    As discussed, in our case, any request that alters the map should finish the entire request, so that requests never interleave and cause inconsistency.
    What is interesting in our case is that the shared data is not memory on the same computer but the order of network events that cause mutation in the memory of the clients applications.

    It should be noted here that the broadcaster itself is already secured via one Mutex per map.
    \gls{sse} guarantees to preserve the order of messages across the network.
    As specified, RFC 8895 \cite{rfc8895sse} describes the data stream as a reliable ordered connection between the server and the client.
    
    \item \textbf{Progress}
    This means that only the threads that execute the critical section should pay for its synchronization.
    We want to place the synchronization mechanism as narrow as possible, for example by having one mechanism (like a Mutex) per map instead of one global mechanism for the section.
\end{enumerate}

\chapter{Related Work}

Thore Fechner developed a web application called Ehtermap to demonstrate real-time synchronization for collaborative editing of geospatial data on a map\cite{ethermap}.

Ethermap uses continuous synchronization of all changes.
In contrast to PermaplanT's Map Editor, Ethermap displays information about all currently connected users and the area of the map users are currently editing.
To handle conflicts and trace changes, Ethermap provides a continuous history feed of all changes on a map.
Users can inspect revisions and restore previous states.

PermaplanT's could benefit from adding visual indicators to signal that other users are working on the same Garden Map.
A history management tool could help users understand changes and experiment more freely, by allowing them to revert changes.

Neogy et al. discusses the challenges of maintaining shared awareness among users while supporting independent exploration within a real-time collaboration application. \cite{collaboration_visualizations} 

To bridge that gap, the article introduces interactive features:
\begin{enumerate}
    \item \textbf{Peeking} Temporarily viewing the state of another user.
    \item \textbf{Tracking} Synchronizing views with the views of another user in real time.
    \item \textbf{Forking} Independent exploration starting from the state of another user.
\end{enumerate}

The concept of forking is interesting because it allows users to diverge from the shared state and experiment with alternative configurations.
In PermaplanT it is not possibly to diverge from the synchronized state of the Garden Map.

Litt et al. present Peritext, a Conflict-Free Replicated Data Type (CRDT) algorithm for collaborative rich text editing \cite{peritext}.

Its focus is to ensure that edits from multiple users (such as changing text, editing the format, deleting characters) merge with the user's intent in mind.
Rather than storing formatting as a tree (like XML), Peritext assigns a unique identifier to each character and stores formatting as spans linked to characters.
Deleted characters still remain in the text as tombstones.

Permaplant's Map Editor could use ideas from CRDTs and Peritext
\begin{enumerate}
    \item \textbf{Commutative Operations} The order of operations in Peritext is order-independent.
    Therefore, there is no need to guarantee the correct order of events.
    \item \textbf{Tombstones} Plants marked as deleted could remain on the map.
\end{enumerate}

\chapter{Methodology}

\section{Motivation}

This chapter explains the two types of tests conducted to answer the research questions.
The motivations for the tests are as following.

\begin{itemize}
    \item \textbf{Performance Test:} The \gls{http} request does not return until the broadcaster concludes, so the latency of each request may increase with the number of \gls{sse} connections.
    We aim to determine how response times scale as more observers receive updates.
    \item \textbf{Correctness Test:} Since there is a race condition in the broadcaster we want to confirm that actions can be broadcasted in the wrong order. 
\end{itemize}

\section{Testing Hardware}

There are two different computers used to conduct the test.

Desktop Computer \textit{Computer A}
\begin{itemize}
  \item Operating System: Linux Mint 22 (Linux Kernel 6.8.0-45-generic)
  \item CPU: Intel i7-5820K (12) @ 3600MHz
  \item RAM: 16 GiB DDR4 @ 2133MHz
  \item Storage: 120 GiB Solid State Drive
\end{itemize}

Laptop \textit{Computer B}
\begin{itemize}
  \item Operating System: Linux Mint 22 (Linux Kernel 6.8.0-41-generic)
  \item CPU: Intel i5-6300U (4) @ 3000Mhz
  \item RAM: 8 GiB DDR4 @ 2133MHz
  \item Storage: 240 GiB Solid State Drive
\end{itemize}

\section{Performance Test}

To evaluate the performance of the event broadcasting mechanism in the PermaplanT Map Editor, we conducted a series of performance tests while simulating an increasing number of concurrent users viewing the same map.
These tests measure the response time for user requests.

\subsection{Simulating Connections}
To simulate multiple users viewing the same map, we developed a Python script \bashsnippet{connect_listener.py}.
\bashsnippet{connect\_listener.py} establishes concurrent connections to the event broadcasting service at the endpoint \urlsnippet{/api/updates}.
The number of connections can be configured through command-line arguments.
We simulated 100 concurrent users on map with the ID of 1 on localhost by executing the following command: 
\begin{lstlisting}[language=bash]
python3 connect\_listener.py --url localhost --map\_id 1 100
\end{lstlisting}
This initiates 100 Python threads (green threads), each of which opens an \gls{sse} connection.  

\subsection{Simulating User Interaction with the Map}
A second Python script emulates a user making modifications to the map.
The script begins by creating a planting on the map and then continuously alters its position by sending an \gls{http} \texttt{PATCH} request to \urlsnippet{api/maps/<map_id>/layers/plants/plantings}.

It can be configured how many request the script makes.
In our benchmark we used the invocation \bashsnippet{python3 make_requests.py --url localhost --map_id 1 100} to make
100 move requests - it deletes the slowest and the fastest measurements and returns the average time each request takes to complete.
    
\subsection{Tests}

Each test is conducted by connecting a number of concurrent users while measuring the request times using the second script. The tests are run both locally and against the production server at \urlsnippet{https://www.permaplant.net}.

\section{Local tests}

The local tests are run on a computer with the following specifications:
\begin{itemize}
  \item Operating System: Linux Mint 22 (Linux Kernel 6.8.0-45-generic)
  \item CPU: Intel i7-5820K (12) @ 3600MHz
  \item RAM: 16 GiB DDR4 @ 2133MHz
  \item Storage: 120 GiB Solid State Drive
\end{itemize}

Each test follows the following steps:
\begin{enumerate}
    \item start the backend (release build)
    \item use the Python script to emulate connected users
    E.g \bashsnippet{connect\_listener.py --map\_id 1 10} for 10 connections
    \item In a different shell execute 200 requests \texttt{make\_request.py 200}
\end{enumerate}

In order to try 2000 concurrent \gls{sse} connections locally we had to adjust the number of maximum open file descriptors using the \texttt{ulimit} command.
The default for this limit on Linux Mint 22 is 1024 (shown by \bashsnippet{ulimit -n}).
We adjusted this limit to 3000 before simulating 2000 concurrent \gls{sse} connection.
Without this adjustment Backend would log \texttt{Too many open files (os error 24)}.

\section{Test against www.permaplant.net}

Our production server is hosted on \urlsnippet{www.permaplant.net}.
On one computer we use the connection script while a different computer on a different network makes the requests.

On the above mentioned computer we simulate our connected users with this invocation: 
\begin{verbatim}
# For 10 connections
connect\_listener.py \
    --url https://www.permaplant.net \
    --map\_id 79 \
    --client\_id "PermaplanT-Prod" \
    10 
\end{verbatim}

On a different computer (Thinkpad T470 i5-6300U) in a different network we simulate the requests:
\texttt{make\_request.py --url https://www.permaplant.net --map\_id 79 --client\_id "PermaplanT-Prod" 200}

\section{Action Order Test}

This test investigates whether actions may reach the client in a different order than the sequence in which their corresponding changes are committed to the database.
To record planting position updates we added new table called \texttt{planting\_log} into our PostgreSQL database, that keeps a log of all moved plantings, with their old and new x and y coordinates.

\begin{lstlisting}[language=sql]
CREATE TABLE IF NOT EXISTS planting_log (
    log_timestamp timestamp DEFAULT clock_timestamp(),
    planting_id uuid NOT NULL,
    old_x int,
    old_y int,
    new_x int, kkm
    new_y int,
    PRIMARY KEY (log_timestamp, planting_id)
);
\end{lstlisting}

A trigger logs every update to the \texttt{plantings} table into \texttt{planting\_log}.

\begin{lstlisting}[language=sql]
CREATE TABLE IF NOT EXISTS planting_log (
    log_timestamp timestamp DEFAULT clock_timestamp(),
    planting_id uuid NOT NULL,
    old_x int,
    old_y int,
    new_x int,
    new_y int,
    PRIMARY KEY (log_timestamp, planting_id)
);

CREATE OR REPLACE FUNCTION log_planting_update()
RETURNS trigger AS $$
BEGIN
    INSERT INTO planting_log (log_timestamp, planting_id, old_x, old_y, new_x, new_y)
    VALUES (clock_timestamp(), OLD.id, OLD.x, OLD.y, NEW.x, NEW.y);
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER log_planting_update_trigger
BEFORE UPDATE ON plantings
FOR EACH ROW
EXECUTE FUNCTION log_planting_update();
\end{lstlisting}

Using a similar connection script from the performance test we recorded all actions into a file. \bashsnippet{connect\_listener.py 1 1> target/actions.txt}

We developed a script called \texttt{attack.py} that move a planting via the \gls{http} \texttt{patch} request.
Lastly, we extracted the database planting\_logs into a file with the same format as \texttt{actions.txt}.
Each line is in the format \texttt{planting\_id | x | y}.
We used the \texttt{diff} program to compare both files line by line.
If we find that the order is not the same we reveal that there is a race condition and events are not sent in the correct order. 
Note that the opposite is not the case: If the order of both files are the same the broadcasting system might not have race conditions or the test may be inadequate of showing it.

\chapter{Results}

The results clearly show that the current implementation of the broadcasting system can support 100 concurrent users.

\section{Performance Test}
\subsection{Local tests}

\begin{table}[h!]
    \centering
    \begin{tabular}{cc}
        \toprule
        \textbf{Connections} & \textbf{Avg Time (200 Requests) in ms} \\
        \midrule
        0 & 6.39 \\
        10 & 6.20 \\
        20 & 6.66 \\
        50 & 6.50 \\
        100 & 6.24 \\
        150 & 6.86 \\
        200 & 7.58 \\
        500 & 9.85 \\
        1000 & 10.97 \\
        2000 & 10.10 \\
        \bottomrule
    \end{tabular}
    \caption{Results of 200 Requests for Different Connection Counts}
\end{table}

\subsection{Test against www.permaplant.net}

\begin{table}[h!]
    \centering
    \begin{tabular}{cc}
        \toprule
        \textbf{Connections} & \textbf{Avg Time (200 Requests) in ms} \\
        \midrule
        0 & 64.06 \\
        10 & 60.24 \\
        20 & 60.81 \\
        50 & 61.52 \\
        100 & 64.76 \\
        150 & 64.55 \\
        200 & 62.42 \\
        \bottomrule
    \end{tabular}
    \caption{Results of 200 Requests for Remote Test}
\end{table}

\section{Action Order Test}

The test moved the same planting on the same time 20,000 in parallel.
On a local setup the likelihood of events out of order increased when we connected more listeners.
With 400 additional connections (+ a 401st connection that keeps track of the received events) there were 34 action received in the wrong order.

\chapter{Discussion}

\section{Performance Test}

\section{Action Order Test}

While the conditions of the test were intentionally designed to trigger the data race, it is questionable whether the data race would happen under real use.
Nevertheless we were able to prove that actions are not guaranteed to be sent out in the correct order.

\section{Possible solutions to the Action ordering problem}

Message ordering is often a problem in distributed systems.

\subsection{Global Event Ordering}

\printglossary[type=\acronymtype,title=Acronyms]

\backmatter

\bibliographystyle{alpha}
\bibliography{thesis}

\end{document}
